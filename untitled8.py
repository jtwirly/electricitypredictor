#!/usr/bin/env python
# coding: utf-8

# Train and fine-tune a GPT-3 model in Azure Machine Learning for predicting electricity prices and consumption

# In[1]:


get_ipython().system('pip install openai')
get_ipython().system('pip install requests')
get_ipython().system('pip install json')


# In[2]:


get_ipython().system('pip install azureml-sdk[automl,notebooks,explain,contrib] openai_secret_manager')


# In[3]:




# In[4]:


get_ipython().system('pip install --upgrade azureml-sdk')


# In[5]:


pip install openai


# In[6]:


from azure.identity import DefaultAzureCredential
from azure.keyvault.secrets import SecretClient
import openai

credential = DefaultAzureCredential()

secret_client = SecretClient(vault_url="https://keyvault1555.vault.azure.net/", credential=credential)
secret = secret_client.get_secret("openai")

openai.api_key = secret.value


# Load and preprocess the historical electricity price and consumption data

# In[7]:


get_ipython().system('pip install pandas')


# In[8]:


from azureml.core import Workspace, Dataset
import pandas as pd

# Load the dataset from the default datastore
default_ds = Workspace.from_config().get_default_datastore()
dataset = Dataset.Tabular.from_delimited_files(default_ds.path('ontario_electricity_demand/ontario_electricity_demand.csv'))

# Convert to Pandas dataframe
df = dataset.to_pandas_dataframe()

# Print the list of columns before setting the date as the index
print("Columns before setting date as index:", df.columns.tolist())

# Convert date column to datetime
df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')

# Set date as index
df.set_index('date', inplace=True)

# Print the list of columns after setting the date as the index
print("Columns after setting date as index:", df.columns.tolist())

# Add additional features (e.g. weather, solar, and wind generation) if available

# Split the data into training and testing sets
train_data = df.loc['2003-01-01':'2018-12-31']
test_data = df.loc['2019-01-01':]

# Scale the data using MinMaxScaler
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
train_data_scaled = scaler.fit_transform(train_data)
test_data_scaled = scaler.transform(test_data)

print(df.columns)
print(df.columns.tolist())


# In[9]:


#test data

import pandas as pd

data = {'hour': [1, 2, 3, 4, 5],
        'hourly_demand': [20000000, 25000000, 30000000, 28000000, 32000000],
        'hourly_average_price': [0.10, 0.12, 0.13, 0.11, 0.14]}

df = pd.DataFrame(data)


# Define a function that generates input sequences for the GPT-3 model based on the preprocessed data. This function should take as input a single historical data point, such as the electricity price and consumption for a specific hour, and generate an input sequence that includes relevant contextual information and a prompt asking the model to predict the price and consumption for the next hour.

# In[10]:


def generate_input_sequence(data_point):
    # Extract relevant features from the data point
    hour = data_point["hour"]
    demand = data_point["hourly_demand"]
    price = data_point["hourly_average_price"]
    
    # Format the features as a string and add relevant contextual information
    #context = f"Current hour: {hour}\nCurrent demand: {demand} kWh\nCurrent price: {price} cents/kWh\n\nPredict the price and demand for the next hour."
    
    # Return the input sequence as a dictionary with the context and prompt
    #return {"context": context, "prompt": "Predict the price and demand for the next hour."}

    ##context = f"Current hour: {hour}\nCurrent demand: {demand} kWh\nCurrent price: {price} cents/kWh\n\n"
    ##prompt = "Please provide the predicted price and demand for the next hour in the format: 'Price: X.XX cents/kWh, Demand: YYYYY.YY kWh'"
    
    ##return {"context": context, "prompt": prompt}

    context = f"Hour: {hour}. Demand: {demand} kWh. Price: {price} cents/kWh. "
    prompt = "Based on this information, predict the electricity price in cents/kWh and demand in kWh for the next hour."
    
    return {"context": context, "prompt": prompt}


# Define a function that generates output sequences from the GPT-3 model, given an input sequence generated by the previous function.

# In[11]:


import requests
import json 

def generate_output_sequence(input_sequence, model_engine="text-davinci-002"):
    print("Generating output sequence...")
    print("Input sequence:", input_sequence)
    # Set up the API request
    api_url = "https://api.openai.com/v1/engines/" + model_engine + "/completions"
    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {openai.api_key}"}
    data = {
        "prompt": f"Based on the information: {input_sequence['context']}, please provide the next hour's electricity price in cents/kWh and demand in kWh in the following format: 'Price: X.XX cents/kWh. Demand: YYYYYY.Y kWh.'",
        "max_tokens": 100,
        "temperature": 0.7,
        "n": 1,
        "stop": "\n"
    }


    #initialize OpenAI API key
    openai.api_key = openai.api_key
  
    #print("data:", data)
    #return data["choices"][0]["text"].strip()

    # Send the API request and parse the response
    output_sequence = ""
    while not output_sequence.strip():
        # Send the API request and parse the response
        response = requests.post(api_url, headers=headers, data=json.dumps(data))
        response_data = response.json()
        print("Response:", response_data)
        output_sequence = response_data["choices"][0]["text"].strip()

        if not output_sequence.strip():
            print("Empty output, retrying...")

    print("Output sequence:", output_sequence)

    return output_sequence


# In[12]:


#test if openai working

##import requests
##import json

##def test_gpt3_api(prompt, model_engine="text-davinci-002"):
##    api_url = "https://api.openai.com/v1/engines/" + model_engine + "/completions"
##    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {openai.api_key}"}
##    data = {
##        "prompt": prompt,
##        "max_tokens": 50,
##        "temperature": 0.5,
##        "n": 1,
##        "stop": "\n"
##    }

##    response = requests.post(api_url, headers=headers, data=json.dumps(data))
##    response_json = response.json()
##    if response.status_code == 200:
##        output_sequence = response_json["choices"][0]["text"].strip()
##        print("Output sequence:", output_sequence)
##    else:
##        print("Error:", response_json)

#initialize OpenAI API key
##openai.api_key = openai.api_key

##test_prompt = "Current hour: {hour}. Current demand: {demand} kWh. Current price: {price} cents/kWh. Predict the price and demand for the next hour."
##test_gpt3_api(test_prompt)


# In[13]:


#test the gpt api

#sample_data_point = test_data.iloc[0]
#input_sequence = generate_input_sequence(sample_data_point)
#output_sequence = generate_output_sequence(input_sequence)
#print("Output sequence:", output_sequence)


# In[19]:


import openai

def generate_response(prompt, max_tokens=1024, temperature=0.7):
    response = openai.Completion.create(
      engine="text-davinci-002",
      prompt=prompt,
      max_tokens=max_tokens,
      n=1,
      stop=None,
      temperature=temperature
    )
    return response["choices"][0]["text"]

try:
    prompt = "The current temperature is 75°F and solar power generation is at 60%, what will be the predicted electricity prices and consumption for the next hour?"
    response = generate_response(prompt, max_tokens=100)
    print(response)
except Exception as e:
    print(f"Error: {e}")
    print("I'm sorry, there was an error processing your request.")


# In[27]:


import openai

# Set up OpenAI API key
openai.api_key = openai.api_key

# Get user input
temperature = input("Enter the current temperature (in °F): ")
solar_power = input("Enter the solar power generation (in %): ")

# Generate input sequence based on user input
input_sequence = f"The current temperature is {temperature}°F and solar power generation is at {solar_power}%, what will be the predicted electricity prices and consumption for the next hour?"

# Generate output sequence from GPT-3 model
def generate_response(prompt, max_tokens=1024, temperature=0.7):
    response = openai.Completion.create(
      engine="text-davinci-002",
      prompt=input_sequence,
      max_tokens=max_tokens,
      n=1,
      stop=None,
      temperature=0.7
    )
    return response["choices"][0]["text"]

try:
    prompt = input_sequence
    response = generate_response(prompt, max_tokens=100)
    print(response)
except Exception as e:
    print(f"Error: {e}")
    print("I'm sorry, there was an error processing your request.")

# Extract predicted price and demand from output sequence
##predicted_price = float(response["choices"][0]["text"].split(": ")[1].split(" ")[0])
##predicted_demand = float(response["choices"][0]["text"].split(": ")[2].split(" ")[0])

# Print the predicted price and demand
##print(f"Predicted price: {predicted_price:.2f} cents/kWh")
##print(f"Predicted demand: {predicted_demand:.2f} kWh")


# Define a function that evaluates the performance of the GPT-3 model by comparing its predictions to the actual historical data for a given time period. This function should take as input the preprocessed historical data, the start and end times for the evaluation period, and the model engine to use.

# In[15]:


import pandas as pd
import openai

# Set up OpenAI API key
openai.api_key = openai.api_key

def evaluate_model(data, start_time, end_time, model_engine="text-davinci-002"):
    print("Starting model evaluation...")
    for i in range(start_time, end_time+1):
        print("Evaluating model...")
        input_sequence = generate_input_sequence(data.iloc[i])
        print("Input sequence:", input_sequence)
        
        # Generate output sequence from GPT-3 model
        output_sequence = generate_output_sequence(input_sequence)
        print("Output sequence:", output_sequence)
        
        # Extract predicted price and demand from output sequence
        predicted_price = float(output_sequence.split(": ")[1].split(" ")[0])
        predicted_demand = float(output_sequence.split(": ")[2].split(" ")[0])
        
        # Extract actual price and demand from the preprocessed data
        actual_price = data.iloc[i]["hourly_average_price"]
        actual_demand = data.iloc[i]["hourly_demand"]
        
        # Calculate prediction error
        price_error = abs(predicted_price - actual_price) / actual_price
        demand_error = abs(predicted_demand - actual_demand) / actual_demand
        
        print(f"Prediction for hour {i}:")
        print(f"Predicted price: {predicted_price:.2f}, Actual price: {actual_price:.2f}, Error: {price_error:.2%}")
        print(f"Predicted demand: {predicted_demand:.2f}, Actual demand: {actual_demand:.2f}, Error: {demand_error:.2%}")
        print("\n")
        
    print("Model evaluation complete.")


# In[16]:


##def evaluate_model(data, start_time, end_time, model_engine="text-davinci-002"):
##    print("Evaluating model...")
    # Initialize lists to store the actual and predicted price and demand values
##    actual_prices = []
##    predicted_prices = []
##    actual_demand = []
##    predicted_demand = []
    
    # Iterate over the time period and generate input and output sequences for each data point
##    for i in range(start_time, end_time):
        # Generate input sequence for current data point
##        input_sequence = generate_input_sequence(data.iloc[i])
        
        # Generate output sequence from GPT-3 model
##        output_sequence = generate_output_sequence(input_sequence, model_engine)
##        print("Output sequence:", output_sequence)

        # Extract predicted price and demand from output sequence
##        predicted_price = float(output_sequence.split(": ")[1].split(" ")[0])
##        predicted_demand = float(output_sequence.split(": ")[2].split(" ")[0])
        
        # Extract actual price and demand from the preprocessed data
##        actual_price = data.iloc[i+1]["hourly_average_price"]
##        actual_demand = data.iloc[i+1]["hourly_demand"]
        
        # Append predicted and actual values to their respective lists
##        predicted_prices.append(predicted_price)
##        actual_prices.append(actual_price)
##        predicted_demand.append(predicted_demand)
##        actual_demand.append(actual_demand)
    
    # Compute and print the mean squared error (MSE) and R-squared (R2) for both price and demand
##    from sklearn.metrics import mean_squared_error, r2_score
    
##    mse_price = mean_squared_error(actual_prices, predicted_prices)
##    r2_price = r2_score(actual_prices, predicted_prices)
##    print(f"Price MSE: {mse_price:.2f}")
##    print(f"Price R2: {r2_price:.2f}")
    
##    mse_demand = mean_squared_error(actual_demand, predicted_demand)
##    r2_demand = r2_score(actual_demand, predicted_demand)
##    print(f"Demand MSE: {mse_demand:.2f}")
##    print(f"Demand R2: {r2_demand:.2f}")


# In[17]:


print("Starting model evaluation...")
evaluate_model(df, 0, len(df)-1)
print("Model evaluation complete.")


# In[18]:


print("Starting model evaluation...")
evaluate_model(test_data, 0, len(test_data)-1)
print("Model evaluation complete.")

